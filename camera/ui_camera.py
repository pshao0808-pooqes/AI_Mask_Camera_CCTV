import streamlit as st
import time
import os
from datetime import datetime
from PIL import Image
from pathlib import Path
from camera import camera_controller
import cv2
import numpy as np
import pandas as pd
import plotly.express as px
import tempfile

def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    defaults = {
        'camera_on': False,
        'auto_scan': False,
        'last_scan_time': 0,
        'select_all_files': False,
        # ê°ì²´ íƒì§€ ê´€ë ¨ ìƒíƒœ
        'detection_results': None,
        'processed_images': {},
        'processing_times': [],
        'performance_metrics': {
            'total_processed': 0,
            'avg_processing_time': 0
        },
        # ì‹¤ì‹œê°„ íƒì§€ ìƒíƒœ
        'realtime_enabled': False,
        'capture_frame': False
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def render_camera_control_tab():
    """ì¹´ë©”ë¼ ì œì–´ íƒ­ ë Œë”ë§"""
    col1, col2 = st.columns([1, 1])
    
    system_info = camera_controller.get_system_info()
    
    with col1:
        st.info(f"**ìš´ì˜ì²´ì œ**: {system_info['os']}")
    with col2:
        camera_running, running_processes = camera_controller.check_camera_status()
        if camera_running:
            st.success(f"ğŸŸ¢ ì¹´ë©”ë¼ ì•± ì‹¤í–‰ ì¤‘ ({len(running_processes)}ê°œ)")
        else:
            st.error("ğŸ”´ ì¹´ë©”ë¼ ì•± ì—†ìŒ")

    # ì»¨íŠ¸ë¡¤ íŒ¨ë„
    st.markdown("### ğŸ® ì¹´ë©”ë¼ ì œì–´")
    col1, col2, col3 = st.columns([1, 1, 2])

    with col1:
        if st.button("ğŸ¥ ì¹´ë©”ë¼ ì‹¤í–‰", use_container_width=True, type="primary"):
            success, message = camera_controller.start_camera()
            if success:
                st.success(message)
                st.session_state.camera_on = True
            else:
                st.error(message)
            time.sleep(0.5)
            st.rerun()

    with col2:
        if st.button("ğŸ”´ ì¹´ë©”ë¼ ì¢…ë£Œ", use_container_width=True, type="secondary"):
            success, message = camera_controller.stop_camera()
            if success:
                st.info(message)
            else:
                st.error(message)
            st.session_state.camera_on = False
            time.sleep(0.5)
            st.rerun()

    with col3:
        if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
            st.rerun()

    # ì‹¤í–‰ ì¤‘ì¸ ì¹´ë©”ë¼ ì•± ì •ë³´
    if running_processes:
        st.markdown("### ğŸ“Š ì‹¤í–‰ ì¤‘ì¸ ì¹´ë©”ë¼ ì•±")
        for i, proc in enumerate(running_processes, 1):
            col1, col2, col3 = st.columns([2, 1, 1])
            with col1:
                st.write(f"**{i}.** {proc['name']}")
            with col2:
                st.write(f"PID: {proc['pid']}")
            with col3:
                st.write(f"ë©”ëª¨ë¦¬: {proc['memory']}")

def render_file_management_tab():
    """íŒŒì¼ ê´€ë¦¬ íƒ­ ë Œë”ë§"""
    st.markdown("### ğŸ“ ì¹´ë©”ë¼ íŒŒì¼ ê´€ë¦¬")
    
    # íŒŒì¼ ìŠ¤ìº” ì„¤ì •
    col1, col2, col3 = st.columns(3)
    with col1:
        scan_hours = st.selectbox(
            "ìŠ¤ìº” ë²”ìœ„",
            [1, 6, 12, 24, 48, 72],
            index=3,
            format_func=lambda x: f"ìµœê·¼ {x}ì‹œê°„"
        )
    
    with col2:
        auto_scan = st.checkbox("ìë™ ìŠ¤ìº”", value=st.session_state.auto_scan)
        st.session_state.auto_scan = auto_scan
    
    with col3:
        if st.button("ğŸ” íŒŒì¼ ìŠ¤ìº”", type="primary"):
            st.session_state.last_scan_time = time.time()
            st.rerun()
    
    # ê¸°ë³¸ ì¹´ë©”ë¼ í´ë” ê°€ì ¸ì˜¤ê¸°
    default_folders = camera_controller.get_default_camera_folders()
    
    if not default_folders:
        st.warning("ê¸°ë³¸ ì¹´ë©”ë¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info(f"ìŠ¤ìº” ëŒ€ìƒ í´ë” ({len(default_folders)}ê°œ): " + 
               ", ".join([f.name for f in default_folders[:3]]) + 
               ("..." if len(default_folders) > 3 else ""))
    
    # íŒŒì¼ ìŠ¤ìº” ë° í‘œì‹œ
    if auto_scan or st.session_state.last_scan_time > 0:
        with st.spinner("íŒŒì¼ì„ ìŠ¤ìº”í•˜ëŠ” ì¤‘..."):
            found_files = camera_controller.scan_camera_files(
                folders=default_folders, 
                limit_hours=scan_hours
            )
        
        if found_files:
            st.success(f"ğŸ“¸ {len(found_files)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
            render_file_list(found_files)
        else:
            st.info(f"ìµœê·¼ {scan_hours}ì‹œê°„ ë‚´ ì¹´ë©”ë¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìë™ ìƒˆë¡œê³ ì¹¨
    if auto_scan:
        st.info("ğŸ”„ ìë™ ìŠ¤ìº”ì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (30ì´ˆë§ˆë‹¤ ìƒˆë¡œê³ ì¹¨)")
        time.sleep(30)
        st.rerun()

def render_file_list(found_files):
    """íŒŒì¼ ëª©ë¡ ë Œë”ë§"""
    # íŒŒì¼ í•„í„°ë§
    col1, col2 = st.columns(2)
    with col1:
        file_type_filter = st.selectbox(
            "íŒŒì¼ íƒ€ì… í•„í„°",
            ["ëª¨ë‘", "ì´ë¯¸ì§€ë§Œ", "ë¹„ë””ì˜¤ë§Œ"]
        )
    
    with col2:
        show_previews = st.checkbox("ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ", value=True)
    
    # í•„í„° ì ìš©
    if file_type_filter == "ì´ë¯¸ì§€ë§Œ":
        filtered_files = [f for f in found_files if f['type'] == 'image']
    elif file_type_filter == "ë¹„ë””ì˜¤ë§Œ":
        filtered_files = [f for f in found_files if f['type'] == 'video']
    else:
        filtered_files = found_files
    
    if not filtered_files:
        st.info("ì„ íƒí•œ í•„í„°ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # íŒŒì¼ ì„ íƒ ë° í‘œì‹œ
    st.markdown("### ğŸ“‹ íŒŒì¼ ëª©ë¡")
    selected_files = []
    
    # ì „ì²´ ì„ íƒ/í•´ì œ ë²„íŠ¼
    col1, col2 = st.columns([1, 3])
    with col1:
        select_all = st.button("âœ… ì „ì²´ ì„ íƒ")
        if select_all:
            st.session_state.select_all_files = True
    
    # íŒŒì¼ ëª©ë¡ í‘œì‹œ
    for i, file_info in enumerate(filtered_files[:20]):
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            is_selected = st.checkbox(
                "ì„ íƒ",
                key=f"file_{i}",
                value=getattr(st.session_state, 'select_all_files', False)
            )
            if is_selected:
                selected_files.append(file_info)
        
        with col2:
            file_time = datetime.fromtimestamp(file_info['modified'])
            st.write(f"**{file_info['name']}**")
            st.caption(f"ğŸ“ {file_info['folder']} | ğŸ“… {file_time.strftime('%Y-%m-%d %H:%M')} | ğŸ“„ {camera_controller.format_file_size(file_info['size'])}")
        
        with col3:
            if show_previews and file_info['type'] == 'image':
                try:
                    img = Image.open(file_info['path'])
                    img.thumbnail((100, 100))
                    st.image(img, caption="ë¯¸ë¦¬ë³´ê¸°")
                except:
                    st.write("ğŸ–¼ï¸ ì´ë¯¸ì§€")
            elif file_info['type'] == 'video':
                st.write("ğŸ¬ ë¹„ë””ì˜¤")
    
    # ì„ íƒëœ íŒŒì¼ì´ ìˆì„ ë•Œ ì‘ì—… ì˜µì…˜
    if selected_files:
        render_file_actions(selected_files)
    
    # 20ê°œ ì´ìƒì¼ ë•Œ ì•Œë¦¼
    if len(filtered_files) > 20:
        st.info(f"ğŸ“Š ì´ {len(filtered_files)}ê°œ íŒŒì¼ ì¤‘ ìµœì‹  20ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤.")

def render_file_actions(selected_files):
    """ì„ íƒëœ íŒŒì¼ì— ëŒ€í•œ ì‘ì—… ì˜µì…˜"""
    st.markdown(f"### ğŸ¯ ì„ íƒëœ íŒŒì¼ ({len(selected_files)}ê°œ)")
    
    # ì €ì¥ ê²½ë¡œ ì„¤ì •
    save_path = st.text_input(
        "ì €ì¥ ê²½ë¡œ",
        value=camera_controller.save_directory,
        help="íŒŒì¼ì„ ì €ì¥í•  í´ë” ê²½ë¡œ"
    )
    camera_controller.save_directory = save_path
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        organize_by_date = st.checkbox("ë‚ ì§œë³„ í´ë” ì •ë¦¬")
    
    with col2:
        if st.button("ğŸ“ í´ë” ìƒì„±"):
            success, message = camera_controller.create_save_directory(save_path)
            if success:
                st.success(message)
            else:
                st.error(message)
    
    with col3:
        if st.button("ğŸ’¾ íŒŒì¼ ë³µì‚¬", type="primary"):
            success, copied_files, errors = camera_controller.copy_files_to_destination(
                selected_files, save_path, organize_by_date
            )
            
            if success:
                st.success(f"âœ… {len(copied_files)}ê°œ íŒŒì¼ì´ ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                if copied_files:
                    with st.expander("ë³µì‚¬ëœ íŒŒì¼ ëª©ë¡"):
                        for filename in copied_files:
                            st.write(f"â€¢ {filename}")
                
                if errors:
                    st.warning(f"âš ï¸ {len(errors)}ê°œ íŒŒì¼ì—ì„œ ì˜¤ë¥˜ ë°œìƒ:")
                    for error in errors:
                        st.write(f"â€¢ {error}")
            else:
                st.error("íŒŒì¼ ë³µì‚¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    with col4:
        if st.button("ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ"):
            success, zip_path = camera_controller.create_zip_archive(selected_files)
            if success:
                with open(zip_path, "rb") as zip_file:
                    st.download_button(
                        label="ğŸ“¥ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                        data=zip_file.read(),
                        file_name=f"camera_files_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                        mime="application/zip"
                    )
                os.unlink(zip_path)
            else:
                st.error(f"ZIP ìƒì„± ì‹¤íŒ¨: {zip_path}")

def render_unified_detection_tab():
    """í†µí•©ëœ ì¹´ë©”ë¼ íƒì§€ íƒ­ ë Œë”ë§"""
    st.markdown("### ğŸ”¬ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ê°ì²´ íƒì§€")
    
    # ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ
    system_info = camera_controller.get_system_info()
    col1, col2, col3 = st.columns(3)
    with col1:
        device_status = "GPU ê°€ì†" if system_info['cuda_available'] else "CPU ëª¨ë“œ"
        device_name = system_info['device_name']
        st.info(f"**ì²˜ë¦¬ ì¥ì¹˜**: {device_status} ({device_name})")
    
    with col2:
        model_status = "ë¡œë“œë¨" if camera_controller.model is not None else "ëŒ€ê¸° ì¤‘"
        st.info(f"**ëª¨ë¸ ìƒíƒœ**: {model_status}")
    
    with col3:
        realtime_status = "í™œì„±í™”" if camera_controller.is_realtime_active() else "ë¹„í™œì„±í™”"
        status_color = "success" if camera_controller.is_realtime_active() else "error"
        getattr(st, status_color)(f"**ì‹¤ì‹œê°„ íƒì§€**: {realtime_status}")
    
    # ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”
    render_detection_pipeline_visual()
    
    # ì¹´ë©”ë¼ ëª¨ë“œ ì„ íƒ
    detection_mode = st.radio(
        "ì¹´ë©”ë¼ ëª¨ë“œ ì„ íƒ",
        ["ì‹¤ì‹œê°„ ì¹´ë©”ë¼", "ì¦‰ì‹œ ì´¬ì˜", "íŒŒì¼ ë¶„ì„"],
        horizontal=True
    )
    
    st.markdown("---")
    
    if detection_mode == "ì‹¤ì‹œê°„ ì¹´ë©”ë¼":
        render_realtime_camera_mode()
    elif detection_mode == "ì¦‰ì‹œ ì´¬ì˜":
        render_instant_photo_mode()
    else:  # íŒŒì¼ ë¶„ì„
        render_file_analysis_mode()

def render_realtime_camera_mode():
    """ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ëª¨ë“œ - OpenCV ìœˆë„ìš° ì‚¬ìš©"""
    st.markdown("#### ğŸ¥ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ íƒì§€ (OpenCV ìœˆë„ìš°)")
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.markdown("**ì„¤ì •**")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ ëª©ë¡
        available_cameras = camera_controller.get_available_cameras()
        
        if not available_cameras:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë‹¤ë¥¸ ì•±ì—ì„œ ì‚¬ìš© ì¤‘ì´ ì•„ë‹Œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        # ì¹´ë©”ë¼ ì„ íƒ
        camera_options = [f"ì¹´ë©”ë¼ {cam['index']} ({cam['resolution']})" for cam in available_cameras]
        selected_camera_idx = st.selectbox(
            "ì¹´ë©”ë¼ ì„ íƒ",
            range(len(camera_options)),
            format_func=lambda x: camera_options[x],
            help="ì‚¬ìš©í•  ì¹´ë©”ë¼ ì„ íƒ"
        )
        selected_camera = available_cameras[selected_camera_idx]['index']
        
        # ì‹ ë¢°ë„ ì„¤ì •
        confidence = st.slider(
            "ì‹ ë¢°ë„ ì„ê³„ê°’",
            0.3, 0.8, 0.5, 0.1,
            help="íƒì§€ ì‹ ë¢°ë„ ì„¤ì •"
        )
        
        # ëª¨ë¸ ì„ íƒ
        model_choice = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["yolov8n-seg.pt", "mask_best"],
            help="ì‚¬ìš©í•  íƒì§€ ëª¨ë¸"
        )
        
        # íƒì§€ ê°„ê²© ì„¤ì •
        detection_interval = st.slider(
            "íƒì§€ ê°„ê²© (í”„ë ˆì„)",
            1, 10, 3,
            help="N í”„ë ˆì„ë§ˆë‹¤ ê°ì²´ íƒì§€ ìˆ˜í–‰"
        )
        
        # ëª¨ë¸ ë¡œë“œ
        if model_choice != camera_controller.selected_model:
            with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."):
                camera_controller.load_model(model_choice)
        
        st.markdown("**ì œì–´**")
        
        # OpenCV ìœˆë„ìš° ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘
        if st.button("ğŸ¥ OpenCV ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner("ì‹¤ì‹œê°„ íƒì§€ ì°½ì„ ì—¬ëŠ” ì¤‘..."):
                success, message = start_opencv_realtime_detection(
                    selected_camera, confidence, detection_interval
                )
            if success:
                st.success(message)
                st.info("OpenCV ì°½ì—ì„œ 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
            else:
                st.error(message)
        
        # ë‹¨ì¼ í”„ë ˆì„ ìº¡ì²˜ ë° ë¶„ì„
        if st.button("ğŸ“¸ ë‹¨ì¼ í”„ë ˆì„ ìº¡ì²˜ & ë¶„ì„", use_container_width=True):
            success, result_data = capture_and_analyze_single_frame(selected_camera, confidence)
            if success:
                st.session_state['single_frame_result'] = result_data
                st.success("í”„ë ˆì„ì´ ìº¡ì²˜ë˜ê³  ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.error("í”„ë ˆì„ ìº¡ì²˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    with col1:
        st.markdown("**ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì •ë³´**")
        
        # ì‹œìŠ¤í…œ ì •ë³´
        system_info = camera_controller.get_system_info()
        col_a, col_b = st.columns(2)
        with col_a:
            device_status = "GPU ê°€ì†" if system_info['cuda_available'] else "CPU ëª¨ë“œ"
            st.info(f"ì²˜ë¦¬ ì¥ì¹˜: {device_status}")
        with col_b:
            model_status = "ë¡œë“œë¨" if camera_controller.model is not None else "ëŒ€ê¸° ì¤‘"
            st.info(f"ëª¨ë¸ ìƒíƒœ: {model_status}")
        
        # OpenCV ì°½ ì‚¬ìš©ë²• ì•ˆë‚´
        st.markdown("**ì‚¬ìš©ë²•:**")
        st.write("1. ì„¤ì •ì„ ì¡°ì •í•œ í›„ 'ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­")
        st.write("2. OpenCV ì°½ì´ ì—´ë¦¬ë©´ì„œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì‹œì‘")
        st.write("3. ì°½ì—ì„œ 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ")
        st.write("4. 'ESC' í‚¤ë¡œ ì¼ì‹œì •ì§€/ì¬ê°œ ê°€ëŠ¥")
        
        # ë‹¨ì¼ í”„ë ˆì„ ê²°ê³¼ í‘œì‹œ
        if 'single_frame_result' in st.session_state:
            st.markdown("**ìµœê·¼ ìº¡ì²˜ ë¶„ì„ ê²°ê³¼:**")
            result = st.session_state['single_frame_result']
            
            # ì´ë¯¸ì§€ í‘œì‹œ
            if result['image'] is not None:
                st.image(result['image'], caption=f"ë¶„ì„ ê²°ê³¼ - ì²˜ë¦¬ì‹œê°„: {result['processing_time']:.3f}ì´ˆ", use_container_width=True)
            
            # í†µê³„ í‘œì‹œ
            col_info1, col_info2, col_info3 = st.columns(3)
            with col_info1:
                st.metric("íƒì§€ëœ ì‚¬ëŒ", result['people_count'])
            with col_info2:
                st.metric("ì„¸ê·¸ë©˜í…Œì´ì…˜", result['segmented_count'])
            with col_info3:
                st.metric("ë§ˆìŠ¤í¬ ì°©ìš©", result['mask_count'])
        
        # ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸
        if st.button("ğŸ¹ ì¹´ë©”ë¼ ì—°ê²° í…ŒìŠ¤íŠ¸"):
            available, message = camera_controller.check_camera_availability(selected_camera)
            if available:
                st.success(f"ì¹´ë©”ë¼ {selected_camera}ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
            else:
                st.error(f"ì¹´ë©”ë¼ {selected_camera}: {message}")

def start_opencv_realtime_detection(camera_index, confidence_threshold, detection_interval):
    """OpenCV ìœˆë„ìš°ì—ì„œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì‹¤í–‰"""
    import threading
    
    def detection_worker():
        cap = cv2.VideoCapture(camera_index)
        if not cap.isOpened():
            return False, "ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        
        # ì¹´ë©”ë¼ ì„¤ì •
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        cap.set(cv2.CAP_PROP_FPS, 30)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # ìœˆë„ìš° ì„¤ì •
        window_name = "ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ - 'q':ì¢…ë£Œ, 'ESC':ì¼ì‹œì •ì§€"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1280, 720)
        
        frame_count = 0
        last_detection_result = None
        paused = False
        
        try:
            while True:
                if not paused:
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    # íƒì§€ ìˆ˜í–‰ (ì§€ì •ëœ ê°„ê²©ë§ˆë‹¤)
                    if frame_count % detection_interval == 0:
                        result_img, detections = camera_controller.detect_objects_optimized(
                            frame, confidence_threshold
                        )
                        last_detection_result = result_img
                    else:
                        # ì´ì „ íƒì§€ ê²°ê³¼ ì‚¬ìš©
                        result_img = last_detection_result if last_detection_result is not None else frame
                    
                    # FPS ë° íƒì§€ ì •ë³´ ì˜¤ë²„ë ˆì´
                    info_text = [
                        f"FPS: {cap.get(cv2.CAP_PROP_FPS):.1f}",
                        f"Frame: {frame_count}",
                        f"People: {len(camera_controller.detected_people)}",
                        f"Segmented: {len(camera_controller.segmented_people)}",
                        f"Masks: {len(camera_controller.mask_wearers)}",
                        f"Confidence: {confidence_threshold}",
                        "'q': ì¢…ë£Œ, 'ESC': ì¼ì‹œì •ì§€/ì¬ê°œ"
                    ]
                    
                    for i, text in enumerate(info_text):
                        y_pos = 30 + (i * 25)
                        cv2.putText(result_img, text, (10, y_pos), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                        cv2.putText(result_img, text, (10, y_pos), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)
                    
                    cv2.imshow(window_name, result_img)
                    frame_count += 1
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):  # 'q' í‚¤ë¡œ ì¢…ë£Œ
                    break
                elif key == 27:  # ESC í‚¤ë¡œ ì¼ì‹œì •ì§€/ì¬ê°œ
                    paused = not paused
                    if paused:
                        cv2.putText(result_img, "PAUSED - Press ESC to resume", 
                                  (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                        cv2.imshow(window_name, result_img)
        
        except Exception as e:
            print(f"ì‹¤ì‹œê°„ íƒì§€ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            cap.release()
            cv2.destroyAllWindows()
    
    # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    thread = threading.Thread(target=detection_worker, daemon=True)
    thread.start()
    
    return True, "ì‹¤ì‹œê°„ íƒì§€ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. OpenCV ì°½ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

def capture_and_analyze_single_frame(camera_index, confidence_threshold):
    """ë‹¨ì¼ í”„ë ˆì„ ìº¡ì²˜ ë° ë¶„ì„"""
    cap = cv2.VideoCapture(camera_index)
    if not cap.isOpened():
        return False, None
    
    try:
        # í”„ë ˆì„ ìº¡ì²˜
        ret, frame = cap.read()
        if not ret:
            return False, None
        
        # ê°ì²´ íƒì§€ ìˆ˜í–‰
        start_time = time.time()
        result_img, detections = camera_controller.detect_objects_optimized(frame, confidence_threshold)
        processing_time = time.time() - start_time
        
        # RGBë¡œ ë³€í™˜ (Streamlit í‘œì‹œìš©)
        result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
        
        # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
        result_data = {
            'image': result_rgb,
            'processing_time': processing_time,
            'people_count': len(camera_controller.detected_people),
            'segmented_count': len(camera_controller.segmented_people),
            'mask_count': len(camera_controller.mask_wearers),
            'detections': detections
        }
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        update_performance_metrics(processing_time, len(detections) if isinstance(detections, pd.DataFrame) else 0)
        
        return True, result_data
        
    except Exception as e:
        print(f"í”„ë ˆì„ ìº¡ì²˜ ì˜¤ë¥˜: {e}")
        return False, None
    finally:
        cap.release()

def render_instant_photo_mode():
    """ì¦‰ì‹œ ì´¬ì˜ ëª¨ë“œ"""
    st.markdown("#### ğŸ“· ì¦‰ì‹œ ì´¬ì˜ ë° ë¶„ì„")
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.markdown("**ì´¬ì˜ ì„¤ì •**")
        
        confidence = st.slider(
            "ì‹ ë¢°ë„ ì„ê³„ê°’",
            0.3, 0.8, 0.5, 0.1,
            help="íƒì§€ ì‹ ë¢°ë„ ì„¤ì •",
            key="instant_confidence"
        )
        
        model_choice = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["yolov8n-seg.pt", "mask_best"],
            help="ì‚¬ìš©í•  íƒì§€ ëª¨ë¸",
            key="instant_model"
        )
        
        # ëª¨ë¸ ë¡œë“œ
        if model_choice != camera_controller.selected_model:
            with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."):
                camera_controller.load_model(model_choice)
        
        auto_analyze = st.checkbox("ìë™ ë¶„ì„", value=True, help="ì´¬ì˜ ì¦‰ì‹œ ìë™ìœ¼ë¡œ ë¶„ì„")
    
    with col1:
        st.markdown("**ì¦‰ì‹œ ì´¬ì˜**")
        
        # Streamlitì˜ camera_input ì‚¬ìš©
        camera_photo = st.camera_input("ì¹´ë©”ë¼ë¡œ ì‚¬ì§„ ì´¬ì˜")
        
        if camera_photo is not None:
            if auto_analyze:
                # ìë™ ë¶„ì„ ìˆ˜í–‰
                with st.spinner("ì´¬ì˜ëœ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                    start_time = time.time()
                    result_img, detections, message = camera_controller.process_streamlit_camera_input(
                        camera_photo, confidence
                    )
                    processing_time = time.time() - start_time
                
                if result_img is not None:
                    # ê²°ê³¼ í‘œì‹œ
                    tab1, tab2 = st.tabs(["ë¶„ì„ ê²°ê³¼", "ì›ë³¸"])
                    
                    with tab1:
                        result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                        st.image(result_rgb, use_container_width=True, 
                                caption=f"ê°ì²´ íƒì§€ ê²°ê³¼ - ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ")
                    
                    with tab2:
                        st.image(camera_photo, use_container_width=True, caption="ì´¬ì˜ëœ ì›ë³¸")
                    
                    # íƒì§€ ì •ë³´ í‘œì‹œ
                    col_result1, col_result2, col_result3 = st.columns(3)
                    with col_result1:
                        st.metric("íƒì§€ëœ ì‚¬ëŒ", len(camera_controller.detected_people))
                    with col_result2:
                        st.metric("ì„¸ê·¸ë©˜í…Œì´ì…˜", len(camera_controller.segmented_people))
                    with col_result3:
                        st.metric("ë§ˆìŠ¤í¬ ì°©ìš©", len(camera_controller.mask_wearers))
                    
                    # ìƒì„¸ ë¶„ì„ ì •ë³´
                    if isinstance(detections, pd.DataFrame) and not detections.empty:
                        with st.expander("ìƒì„¸ ë¶„ì„ ê²°ê³¼"):
                            st.dataframe(detections, use_container_width=True)
                    
                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                    update_performance_metrics(processing_time, len(detections) if isinstance(detections, pd.DataFrame) else 0)
                    
                    st.success(f"ë¶„ì„ ì™„ë£Œ! ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
                else:
                    st.error(f"ë¶„ì„ ì‹¤íŒ¨: {message}")
            else:
                # ìˆ˜ë™ ë¶„ì„
                st.image(camera_photo, use_container_width=True, caption="ì´¬ì˜ëœ ì‚¬ì§„")
                
                if st.button("ğŸ” ì´ë¯¸ì§€ ë¶„ì„í•˜ê¸°", type="primary"):
                    with st.spinner("ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                        start_time = time.time()
                        result_img, detections, message = camera_controller.process_streamlit_camera_input(
                            camera_photo, confidence
                        )
                        processing_time = time.time() - start_time
                    
                    if result_img is not None:
                        result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                        st.image(result_rgb, use_container_width=True, caption="ë¶„ì„ ê²°ê³¼")
                        st.success(f"ë¶„ì„ ì™„ë£Œ! ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
                    else:
                        st.error(f"ë¶„ì„ ì‹¤íŒ¨: {message}")

def render_file_analysis_mode():
    """íŒŒì¼ ë¶„ì„ ëª¨ë“œ"""
    st.markdown("#### ğŸ“ ì €ì¥ëœ íŒŒì¼ ë¶„ì„")
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.markdown("**ë¶„ì„ ì„¤ì •**")
        
        confidence = st.slider(
            "ì‹ ë¢°ë„ ì„ê³„ê°’",
            0.3, 0.8, 0.5, 0.1,
            help="íƒì§€ ì‹ ë¢°ë„ ì„¤ì •",
            key="file_confidence"
        )
        
        model_choice = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["yolov8n-seg.pt", "mask_best"],
            help="ì‚¬ìš©í•  íƒì§€ ëª¨ë¸",
            key="file_model"
        )
        
        show_original = st.checkbox("ì›ë³¸ ì´ë¯¸ì§€ ë¹„êµ", value=True, key="file_show_original")
    
    with col1:
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ë¶„ì„í•  ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì—…ë¡œë“œ",
            type=['jpg', 'jpeg', 'png', 'bmp', 'tiff', 'mp4', 'avi', 'mov', 'mkv'],
            help="ì¹´ë©”ë¼ë¡œ ì´¬ì˜í•œ ì´ë¯¸ì§€ë‚˜ ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )
        
        if uploaded_file is not None:
            # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
            file_extension = uploaded_file.name.split('.')[-1].lower()
            
            if file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
                process_uploaded_image(uploaded_file, confidence, model_choice, show_original)
            elif file_extension in ['mp4', 'avi', 'mov', 'mkv']:
                process_uploaded_video(uploaded_file, confidence)

def render_detection_pipeline_visual():
    """ê°ì²´ íƒì§€ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”"""
    st.markdown("#### ğŸ”„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        people_count = len(camera_controller.detected_people)
        status = "ğŸŸ¢" if people_count > 0 else "ğŸ”´"
        st.markdown(f"""
        <div style="border-left: 4px solid #667eea; padding: 1rem; background: #f8f9fa; border-radius: 0 8px 8px 0;">
            <h5>{status} 1ë‹¨ê³„: ì‚¬ëŒ íƒì§€</h5>
            <p>Lìí˜• ê²½ê³„ìƒì</p>
            <strong>{people_count}ëª… íƒì§€ë¨</strong>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        seg_count = len(camera_controller.segmented_people)
        status = "ğŸŸ¢" if seg_count > 0 else "ğŸ”´"
        st.markdown(f"""
        <div style="border-left: 4px solid #667eea; padding: 1rem; background: #f8f9fa; border-radius: 0 8px 8px 0;">
            <h5>{status} 2ë‹¨ê³„: ì„¸ê·¸ë©˜í…Œì´ì…˜</h5>
            <p>í”½ì…€ ë‹¨ìœ„ ë¶„í•  ë§ˆìŠ¤í¬</p>
            <strong>{seg_count}ëª… ë¶„í• ë¨</strong>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        mask_count = len(camera_controller.mask_wearers)
        status = "ğŸŸ¢" if mask_count > 0 else "ğŸ”´"
        st.markdown(f"""
        <div style="border-left: 4px solid #667eea; padding: 1rem; background: #f8f9fa; border-radius: 0 8px 8px 0;">
            <h5>{status} 3ë‹¨ê³„: ë§ˆìŠ¤í¬ íƒì§€</h5>
            <p>ë‹¤ì´ì•„ëª¬ë“œ ì»¤ì„œ í‘œì‹œ</p>
            <strong>{mask_count}ê°œ ë§ˆìŠ¤í¬ íƒì§€ë¨</strong>
        </div>
        """, unsafe_allow_html=True)

def process_uploaded_image(uploaded_file, confidence, model_choice, show_original):
    """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì²˜ë¦¬"""
    # ëª¨ë¸ ì„¤ì •
    if model_choice != camera_controller.selected_model:
        with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."):
            camera_controller.load_model(model_choice)
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(uploaded_file)
    img_array = np.array(image)
    
    # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (RGB -> BGR)
    if len(img_array.shape) == 3:
        img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
    else:
        img_bgr = img_array
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("**ì²˜ë¦¬ ê²°ê³¼**")
        
        # ì²˜ë¦¬ ì‹œì‘
        start_time = time.time()
        
        with st.spinner("ìˆœì°¨ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘..."):
            result_img, detections = camera_controller.detect_objects_optimized(img_bgr, confidence)
        
        processing_time = time.time() - start_time
        
        # ê²°ê³¼ í‘œì‹œ
        if show_original:
            tab1, tab2 = st.tabs(["ì²˜ë¦¬ ê²°ê³¼", "ì›ë³¸"])
            with tab1:
                result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                st.image(result_rgb, use_container_width=True, caption="ê°ì²´ íƒì§€ ê²°ê³¼")
            with tab2:
                st.image(image, use_container_width=True, caption="ì›ë³¸ ì´ë¯¸ì§€")
        else:
            result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
            st.image(result_rgb, use_container_width=True, caption="ê°ì²´ íƒì§€ ê²°ê³¼")
        
        st.success(f"ì²˜ë¦¬ ì™„ë£Œ! ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        update_performance_metrics(processing_time, len(detections))
    
    with col2:
        st.markdown("**ë¶„ì„ ë³´ê³ ì„œ**")
        
        # ë‹¨ê³„ë³„ ê²°ê³¼
        stages_data = {
            'ë‹¨ê³„': ['ì‚¬ëŒ íƒì§€', 'ì„¸ê·¸ë©˜í…Œì´ì…˜', 'ë§ˆìŠ¤í¬ íƒì§€'],
            'ê°œìˆ˜': [
                len(camera_controller.detected_people),
                len(camera_controller.segmented_people),
                len(camera_controller.mask_wearers)
            ],
            'ìƒíƒœ': ['âœ…' if count > 0 else 'âŒ' for count in [
                len(camera_controller.detected_people),
                len(camera_controller.segmented_people),
                len(camera_controller.mask_wearers)
            ]]
        }
        
        df = pd.DataFrame(stages_data)
        st.dataframe(df, use_container_width=True)
        
        # ìƒì„¸ ì •ë³´
        if len(detections) > 0:
            st.markdown("**íƒì§€ ìƒì„¸**")
            detection_summary = detections['name'].value_counts()
            for obj_type, count in detection_summary.items():
                st.write(f"â€¢ {obj_type}: {count}ê°œ")

def process_uploaded_video(uploaded_video, confidence):
    """ì—…ë¡œë“œëœ ë¹„ë””ì˜¤ ì²˜ë¦¬"""
    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:
        tmp.write(uploaded_video.read())
        video_path = tmp.name
    
    try:
        # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error("ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ í”„ë ˆì„", f"{total_frames:,}")
        with col2:
            st.metric("FPS", f"{fps:.1f}")
        with col3:
            st.metric("ê¸¸ì´", f"{duration:.1f}ì´ˆ")
        
        # ì²« ë²ˆì§¸ í”„ë ˆì„ ì²˜ë¦¬
        ret, frame = cap.read()
        if ret:
            start_time = time.time()
            with st.spinner("ë¹„ë””ì˜¤ ì²« í”„ë ˆì„ ë¶„ì„ ì¤‘..."):
                result_img, detections = camera_controller.detect_objects_optimized(frame, confidence)
            processing_time = time.time() - start_time
            
            # ê²°ê³¼ í‘œì‹œ
            col1, col2 = st.columns([2, 1])
            
            with col1:
                tab1, tab2 = st.tabs(["ë¶„ì„ ê²°ê³¼", "ì›ë³¸ í”„ë ˆì„"])
                with tab1:
                    result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                    st.image(result_rgb, use_container_width=True, caption="ì²« í”„ë ˆì„ ë¶„ì„ ê²°ê³¼")
                with tab2:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    st.image(frame_rgb, use_container_width=True, caption="ì›ë³¸ ì²« í”„ë ˆì„")
            
            with col2:
                st.markdown("**ë¶„ì„ ë³´ê³ ì„œ**")
                
                # ì²˜ë¦¬ ì‹œê°„
                st.metric("ì²˜ë¦¬ ì‹œê°„", f"{processing_time:.3f}ì´ˆ")
                
                # ë‹¨ê³„ë³„ ê²°ê³¼
                stages_data = {
                    'ë‹¨ê³„': ['ì‚¬ëŒ íƒì§€', 'ì„¸ê·¸ë©˜í…Œì´ì…˜', 'ë§ˆìŠ¤í¬ íƒì§€'],
                    'ê°œìˆ˜': [
                        len(camera_controller.detected_people),
                        len(camera_controller.segmented_people),
                        len(camera_controller.mask_wearers)
                    ]
                }
                
                df = pd.DataFrame(stages_data)
                st.dataframe(df, use_container_width=True)
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            update_performance_metrics(processing_time, len(detections))
        else:
            st.error("ë¹„ë””ì˜¤ ì²« í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        cap.release()
        
    except Exception as e:
        st.error(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(video_path):
            os.unlink(video_path)

def render_detection_analytics():
    """íƒì§€ ë¶„ì„ ê²°ê³¼ ë Œë”ë§"""
    st.markdown("#### ğŸ“Š ë¶„ì„ í†µê³„")
    
    processing_times = st.session_state.get('processing_times', [])
    
    if not processing_times:
        st.info("ì•„ì§ ë¶„ì„í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë‚˜ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•´ë³´ì„¸ìš”.")
        return
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # ì²˜ë¦¬ ì‹œê°„ ì¶”ì´ ì°¨íŠ¸
        if len(processing_times) > 1:
            df_times = pd.DataFrame({
                'ìˆœì„œ': range(1, len(processing_times) + 1),
                'ì²˜ë¦¬ì‹œê°„': processing_times
            })
            
            fig = px.line(df_times, x='ìˆœì„œ', y='ì²˜ë¦¬ì‹œê°„', 
                         title="íŒŒì¼ë³„ ì²˜ë¦¬ ì‹œê°„ ì¶”ì´")
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
            
            # ì²˜ë¦¬ ì‹œê°„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
            fig2 = px.histogram(x=processing_times, nbins=10, title="ì²˜ë¦¬ ì‹œê°„ ë¶„í¬")
            fig2.update_layout(height=300)
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.info("ì°¨íŠ¸ë¥¼ í‘œì‹œí•˜ë ¤ë©´ 2ê°œ ì´ìƒì˜ íŒŒì¼ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.")
    
    with col2:
        # í†µê³„ ìš”ì•½
        st.markdown("**í†µê³„ ìš”ì•½**")
        metrics = st.session_state.performance_metrics
        
        st.metric("ì´ ì²˜ë¦¬ëœ íŒŒì¼", metrics['total_processed'])
        st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{metrics['avg_processing_time']:.3f}ì´ˆ")
        
        if processing_times:
            st.metric("ìµœê·¼ ì„¸ì…˜ í‰ê· ", f"{sum(processing_times)/len(processing_times):.3f}ì´ˆ")
            st.metric("ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„", f"{max(processing_times):.3f}ì´ˆ")
            st.metric("ìµœì†Œ ì²˜ë¦¬ ì‹œê°„", f"{min(processing_times):.3f}ì´ˆ")

def update_performance_metrics(processing_time, detection_count):
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
    # ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡
    if 'processing_times' not in st.session_state:
        st.session_state.processing_times = []
    
    st.session_state.processing_times.append(processing_time)
    
    # ìµœê·¼ 50ê°œ ê¸°ë¡ë§Œ ìœ ì§€
    if len(st.session_state.processing_times) > 50:
        st.session_state.processing_times.pop(0)
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    metrics = st.session_state.performance_metrics
    metrics['total_processed'] += 1
    
    # ì ì§„ì  í‰ê·  ê³„ì‚°
    if metrics['avg_processing_time'] == 0:
        metrics['avg_processing_time'] = processing_time
    else:
        metrics['avg_processing_time'] = (metrics['avg_processing_time'] + processing_time) / 2

def render_settings_tab():
    """ì„¤ì • íƒ­ ë Œë”ë§"""
    st.markdown("### âš™ï¸ ì„¤ì •")
    
    # ê¸°ë³¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
    st.markdown("#### ğŸ“ ê¸°ë³¸ ì €ì¥ ê²½ë¡œ")
    default_save_path = st.text_input(
        "ê¸°ë³¸ ì €ì¥ í´ë”",
        value=camera_controller.save_directory
    )
    
    if st.button("ğŸ“ ì €ì¥ ê²½ë¡œ ì ìš©"):
        camera_controller.save_directory = default_save_path
        st.success("ì €ì¥ ê²½ë¡œê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ê°ì²´ íƒì§€ ì„¤ì •
    st.markdown("#### ğŸ”¬ ê°ì²´ íƒì§€ ì„¤ì •")
    
    col1, col2 = st.columns(2)
    with col1:
        default_confidence = st.slider(
            "ê¸°ë³¸ ì‹ ë¢°ë„ ì„ê³„ê°’",
            0.1, 0.9, 0.5, 0.1,
            help="íƒì§€ë¥¼ ìœ„í•œ ê¸°ë³¸ ì‹ ë¢°ë„ ì„¤ì •"
        )
    
    with col2:
        use_gpu = st.checkbox(
            "GPU ê°€ì† ì‚¬ìš©",
            value=camera_controller.performance_settings['use_gpu_acceleration'],
            help="ê°€ëŠ¥í•œ ê²½ìš° GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ë¦¬ ì†ë„ í–¥ìƒ"
        )
    
    # ì„¤ì • ì €ì¥
    if st.button("ğŸ’¾ ì„¤ì • ì €ì¥"):
        camera_controller.performance_settings.update({
            'confidence_threshold': default_confidence,
            'use_gpu_acceleration': use_gpu
        })
        st.success("ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

def render_sidebar():
    """ì‚¬ì´ë“œë°” ë Œë”ë§"""
    with st.sidebar:
        st.header("ì‹œìŠ¤í…œ ì •ë³´")
        
        system_info = camera_controller.get_system_info()
        st.markdown("### ì¹´ë©”ë¼ ì•± ì§€ì›")
        
        for app in system_info['supported_apps']:
            st.write(f"- **{app}**")
        
        if system_info['system'] == "Linux":
            st.markdown("#### ì„¤ì¹˜ ëª…ë ¹ì–´:")
            st.code("sudo apt install cheese", language="bash")
        
        # ê°ì²´ íƒì§€ ì •ë³´
        st.markdown("---")
        st.markdown("### ğŸ”¬ ê°ì²´ íƒì§€ ì •ë³´")
        device_status = "GPU ê°€ì†" if system_info['cuda_available'] else "CPU ëª¨ë“œ"
        st.write(f"**ì²˜ë¦¬ ì¥ì¹˜**: {device_status}")
        st.write(f"**ì¥ì¹˜ëª…**: {system_info['device_name']}")
        
        # ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì •ë³´
        available_cameras = camera_controller.get_available_cameras()
        if available_cameras:
            st.markdown("### ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼")
            for cam in available_cameras:
                st.write(f"- **{cam['name']}** ({cam['resolution']})")
        
        # ì‹¤ì‹œê°„ íƒì§€ ìƒíƒœ
        if camera_controller.is_realtime_active():
            st.success("ì‹¤ì‹œê°„ íƒì§€ í™œì„±í™”")
        else:
            st.info("ì‹¤ì‹œê°„ íƒì§€ ë¹„í™œì„±í™”")
        
        st.markdown("---")
        st.markdown("### ğŸ› ï¸ ê¸°ëŠ¥")
        st.write("âœ… ì¹´ë©”ë¼ ì•± ì œì–´")
        st.write("âœ… ìë™ íŒŒì¼ ìŠ¤ìº”")
        st.write("âœ… íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
        st.write("âœ… ì›í•˜ëŠ” ìœ„ì¹˜ë¡œ ë³µì‚¬")
        st.write("âœ… ZIP ì••ì¶• ë‹¤ìš´ë¡œë“œ")
        st.write("âœ… ë‚ ì§œë³„ í´ë” ì •ë¦¬")
        st.write("ğŸ†• ìˆœì°¨ ê°ì²´ íƒì§€")
        st.write("ğŸ†• ì‚¬ëŒ/ë§ˆìŠ¤í¬ ì¸ì‹")
        st.write("ğŸ†• ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¶„ì„")

def run_camera_ui_standalone():
    """ë…ë¦½ ì‹¤í–‰ìš© ì¹´ë©”ë¼ UI"""
    st.set_page_config(
        page_title="ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ",
        page_icon="ğŸ“¹",
        layout="wide"
    )
    
    init_session_state()
    
    st.title("ğŸ“¹ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ê°ì²´ íƒì§€ ë° íŒŒì¼ ê´€ë¦¬ ì‹œìŠ¤í…œ")
    st.markdown("---")
    
    # íƒ­ìœ¼ë¡œ ê¸°ëŠ¥ ë¶„ë¦¬
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ® ì¹´ë©”ë¼ ì œì–´", 
        "ğŸ“ íŒŒì¼ ê´€ë¦¬", 
        "ğŸ”¬ ê°ì²´ íƒì§€",
        "ğŸ“Š ë¶„ì„ ê²°ê³¼",
        "âš™ï¸ ì„¤ì •"
    ])
    
    with tab1:
        render_camera_control_tab()
    
    with tab2:
        render_file_management_tab()
    
    with tab3:
        render_unified_detection_tab()
    
    with tab4:
        render_detection_analytics()
    
    with tab5:
        render_settings_tab()
    
    render_sidebar()
    
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: gray;'>"
        "ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ê°ì²´ íƒì§€ ì‹œìŠ¤í…œ | ì´¬ì˜ â†’ ì‹¤ì‹œê°„ ë¶„ì„ â†’ ì €ì¥ â†’ ê´€ë¦¬"
        "</div>", 
        unsafe_allow_html=True
    )

def run_camera_ui():
    """ê¸°ë³¸ ì¹´ë©”ë¼ UI í•¨ìˆ˜ - í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€"""
    run_camera_ui_standalone()