import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import tempfile
import os
import time
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import threading
import asyncio

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = ['DejaVu Sans', 'Malgun Gothic', 'AppleGothic', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# ê³ ê¸‰ ìŠ¤íƒ€ì¼ CSS
CUSTOM_CSS = """
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px 0 rgba(31, 38, 135, 0.37);
    }
    
    .metric-card {
        background: rgba(255, 255, 255, 0.1);
        backdrop-filter: blur(10px);
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border: 1px solid rgba(255, 255, 255, 0.2);
        box-shadow: 0 4px 15px 0 rgba(31, 38, 135, 0.37);
    }
    
    .status-indicator {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-right: 8px;
    }
    
    .status-active { background-color: #4CAF50; }
    .status-inactive { background-color: #f44336; }
    .status-processing { background-color: #ff9800; }
    
    .stage-card {
        border-left: 4px solid #667eea;
        padding: 1rem;
        margin: 1rem 0;
        background: #f8f9fa;
        border-radius: 0 8px 8px 0;
    }
    
    .processing-pipeline {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 1rem;
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 10px;
        margin: 1rem 0;
    }
    
    .pipeline-step {
        text-align: center;
        flex: 1;
        position: relative;
    }
    
    .pipeline-arrow {
        font-size: 24px;
        color: #667eea;
        margin: 0 10px;
    }
</style>
"""

class PremiumUI:
    def __init__(self):
        self.init_page_config()
        self.init_session_state()
        self.load_custom_css()


    def run_standalone(self):
        """ë…ë¦½ ì‹¤í–‰ìš© ë¹„ë””ì˜¤ UI - main.pyì—ì„œ í˜¸ì¶œí•˜ì§€ ì•Šì„ ë•Œ ì‚¬ìš©"""
        # ë©”ì¸ í—¤ë” ë Œë”ë§
        self.render_header()
        
        # ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ê°’ë“¤ ê°€ì ¸ì˜¤ê¸°
        settings = self.render_advanced_sidebar()
        
        # ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ë Œë”ë§
        self.render_processing_pipeline_visual()
        
        # ë©”ì¸ íƒ­ êµ¬ì„± (ì´ë¯¸ì§€ ë¶„ì„, ë¹„ë””ì˜¤ ë¶„ì„, ì‹¤ì‹œê°„ ë¶„ì„)
        tab1, tab2, tab3 = st.tabs(["ì´ë¯¸ì§€ ë¶„ì„", "ë¹„ë””ì˜¤ ë¶„ì„", "ì‹¤ì‹œê°„ ë¶„ì„"])
        
        with tab1:
            self.render_image_detection_mode(settings)
        
        with tab2:
            self.render_video_analysis_mode(settings)
        
        with tab3:
            self.render_analytics_dashboard()

    def run(self):
        """ë©”ì¸ UI ì‹¤í–‰ í•¨ìˆ˜ - í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€"""
        self.run_standalone()
        
    def init_page_config(self):
        """í˜ì´ì§€ êµ¬ì„± ì„¤ì •"""
        st.set_page_config(
            page_title="ê³ ê¸‰ YOLO íƒì§€ ì‹œìŠ¤í…œ",
            page_icon="ğŸ”¬",
            layout="wide",
            initial_sidebar_state="expanded"
        )
    
    def init_session_state(self):
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        defaults = {
            'video_path': None,
            'current_frame': 0,
            'total_frames': 0,
            'fps': 30,
            'is_playing': False,
            'playback_speed': 1.0,
            'last_detection_time': None,
            'processing_history': [],
            'processing_times': [],
            'performance_metrics': {
                'total_processed': 0,
                'avg_processing_time': 0,
                'detection_accuracy': 0
            },
            'video_playing_thread': None,
            'stop_video': False,
            'batch_results': None,
            'processing_complete': False,
            'is_processing': False,
            'auto_show_results': True  # ìë™ ê²°ê³¼ í‘œì‹œ í”Œë˜ê·¸
        }
        
        for key, value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value
    
    def load_custom_css(self):
        """ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼ ë¡œë“œ"""
        st.markdown(CUSTOM_CSS, unsafe_allow_html=True)
    
    def render_header(self):
        """ë©”ì¸ í—¤ë” ë Œë”ë§"""
        st.markdown("""
        <div class="main-header">
            <h1>ğŸ”¬ ê³ ê¸‰ ìˆœì°¨ YOLO íƒì§€ ì‹œìŠ¤í…œ</h1>
            <p>ì „ë¬¸ê°€ê¸‰ ê°ì²´ íƒì§€ ë° ìˆœì°¨ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸</p>
        </div>
        """, unsafe_allow_html=True)
    
    def render_processing_pipeline_visual(self):
        """ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™”"""
        from video import video_detector
        
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col1:
            people_count = len(video_detector.detected_people)
            status = "active" if people_count > 0 else "inactive"
            st.markdown(f"""
            <div class="stage-card">
                <h4><span class="status-indicator status-{status}"></span>1ë‹¨ê³„: ì‚¬ëŒ íƒì§€</h4>
                <p>Lìí˜• ê²½ê³„ìƒì</p>
                <strong>{people_count}ëª… íƒì§€ë¨</strong>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            seg_count = len(video_detector.segmented_people)
            status = "active" if seg_count > 0 else "inactive"
            st.markdown(f"""
            <div class="stage-card">
                <h4><span class="status-indicator status-{status}"></span>2ë‹¨ê³„: ì„¸ê·¸ë©˜í…Œì´ì…˜</h4>
                <p>í”½ì…€ ë‹¨ìœ„ ë¶„í•  ë§ˆìŠ¤í¬</p>
                <strong>{seg_count}ëª… ë¶„í• ë¨</strong>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            mask_count = len(video_detector.mask_wearers)
            status = "active" if mask_count > 0 else "inactive"
            st.markdown(f"""
            <div class="stage-card">
                <h4><span class="status-indicator status-{status}"></span>3ë‹¨ê³„: ë§ˆìŠ¤í¬ íƒì§€</h4>
                <p>ì»¤ì„œ í‘œì‹œê¸°ë¡œ ë§ˆìŠ¤í¬ í‘œì‹œ</p>
                <strong>{mask_count}ê°œ ë§ˆìŠ¤í¬ íƒì§€ë¨</strong>
            </div>
            """, unsafe_allow_html=True)
    
    def render_advanced_sidebar(self):
        """ê³ ê¸‰ ì‚¬ì´ë“œë°” ë Œë”ë§"""
        with st.sidebar:
            st.markdown("## ì œì–´ íŒ¨ë„")
            
            with st.expander("ëª¨ë¸ êµ¬ì„±", expanded=True):
                model_choice = st.selectbox(
                    "íƒì§€ ëª¨ë¸",
                    ["yolov8n-seg.pt", "mask_best"],
                    help="ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì„ íƒ",
                    key="sidebar_model_choice"
                )
                
                device_info = "CPU ëª¨ë“œ" if not torch.cuda.is_available() else f"GPU: {torch.cuda.get_device_name()}"
                st.info(device_info)
            
            with st.expander("ì„±ëŠ¥ ì„¤ì •", expanded=True):
                detection_interval = st.slider(
                    "íƒì§€ ê°„ê²©",
                    min_value=1, max_value=10, value=3,
                    help="N í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬",
                    key="sidebar_detection_interval"
                )
                
                confidence_threshold = st.slider(
                    "ì‹ ë¢°ë„ ì„ê³„ê°’",
                    min_value=0.1, max_value=0.9, value=0.5, step=0.1,
                    help="íƒì§€ë¥¼ ìœ„í•œ ìµœì†Œ ì‹ ë¢°ë„",
                    key="sidebar_confidence_threshold"
                )
                
                target_fps = st.slider(
                    "ëª©í‘œ FPS",
                    min_value=15, max_value=60, value=30,
                    help="ëª©í‘œ ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜",
                    key="sidebar_target_fps"
                )
            
            with st.expander("ì„±ëŠ¥ ë©”íŠ¸ë¦­", expanded=False):
                self.render_performance_metrics()
            
            with st.expander("ê³ ê¸‰ ì˜µì…˜", expanded=False):
                enable_history = st.checkbox("ì²˜ë¦¬ íˆìŠ¤í† ë¦¬ í™œì„±í™”", value=True, key="enable_history")
                enable_analytics = st.checkbox("ë¶„ì„ í™œì„±í™”", value=True, key="enable_analytics")
                auto_save_results = st.checkbox("ê²°ê³¼ ìë™ ì €ì¥", value=False, key="auto_save_results")
            
            return {
                'model_choice': model_choice,
                'detection_interval': detection_interval,
                'confidence_threshold': confidence_threshold,
                'target_fps': target_fps,
                'enable_history': enable_history,
                'enable_analytics': enable_analytics,
                'auto_save_results': auto_save_results
            }
    
    def render_performance_metrics(self):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ í‘œì‹œ"""
        metrics = st.session_state.performance_metrics
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì²˜ë¦¬ë¨", metrics['total_processed'])
        with col2:
            st.metric("í‰ê·  ì‹œê°„", f"{metrics['avg_processing_time']:.3f}ì´ˆ")
    
    def render_image_detection_mode(self, settings):
        """ì´ë¯¸ì§€ íƒì§€ ëª¨ë“œ ë Œë”ë§"""
        st.markdown("## ì „ë¬¸ ì´ë¯¸ì§€ ë¶„ì„")
        
        col1, col2 = st.columns([3, 1])
        
        with col2:
            st.markdown("### ë¶„ì„ ì„¤ì •")
            confidence = st.slider(
                "ë¶„ì„ ì‹ ë¢°ë„",
                0.1, 0.9, settings['confidence_threshold'], 0.1,
                key="image_analysis_confidence"
            )
            
            show_heatmap = st.checkbox("ì‹ ë¢°ë„ íˆíŠ¸ë§µ í‘œì‹œ", value=False, key="show_heatmap")
            detailed_report = st.checkbox("ìƒì„¸ ë³´ê³ ì„œ ìƒì„±", value=True, key="detailed_report")
            
        with col1:
            uploaded_file = st.file_uploader(
                "ë¶„ì„í•  ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                type=['jpg', 'jpeg', 'png', 'bmp', 'webp'],
                help="ì§€ì› í˜•ì‹: JPG, PNG, BMP, WEBP",
                key="image_uploader"
            )
            
            if uploaded_file is not None:
                self.process_uploaded_image(uploaded_file, confidence, show_heatmap, detailed_report)
    
    def process_uploaded_image(self, uploaded_file, confidence, show_heatmap, detailed_report):
        """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë¶„ì„"""
        from video import video_detector
        
        image = Image.open(uploaded_file)
        img_array = np.array(image)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("### ì²˜ë¦¬ ê²°ê³¼")
            
            start_time = time.time()
            
            with st.spinner("ìˆœì°¨ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘..."):
                result_img, detections = video_detector.detect_objects_optimized(img_array, confidence)
                
            processing_time = time.time() - start_time
            
            result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
            st.image(result_rgb, use_container_width=True)
            
            st.success(f"âœ… {processing_time:.3f}ì´ˆ ë§Œì— ì²˜ë¦¬ ì™„ë£Œ")
            
            self.update_performance_metrics(processing_time, len(detections))
        
        with col2:
            st.markdown("### ë¶„ì„ ë³´ê³ ì„œ")
            
            stages_data = {
                'ë‹¨ê³„': ['ì‚¬ëŒ íƒì§€', 'ì„¸ê·¸ë©˜í…Œì´ì…˜', 'ë§ˆìŠ¤í¬ íƒì§€'],
                'ê°œìˆ˜': [
                    len(video_detector.detected_people),
                    len(video_detector.segmented_people),
                    len(video_detector.mask_wearers)
                ],
                'ìƒíƒœ': ['âœ…' if count > 0 else 'âŒ' for count in [
                    len(video_detector.detected_people),
                    len(video_detector.segmented_people),
                    len(video_detector.mask_wearers)
                ]]
            }
            
            df = pd.DataFrame(stages_data)
            st.dataframe(df, use_container_width=True)
            
            if detailed_report and len(detections) > 0:
                st.markdown("### ìƒì„¸ ë¶„ì„")
                
                if len(detections) > 0:
                    fig = px.histogram(
                        detections, x='confidence',
                        title="ì‹ ë¢°ë„ ë¶„í¬",
                        nbins=20
                    )
                    fig.update_layout(height=300)
                    st.plotly_chart(fig, use_container_width=True, key="image_confidence_histogram")
    
    def video_playback_thread(self, video_path, target_fps, enable_detection, confidence):
        """ë¹„ë””ì˜¤ ì¬ìƒì„ ìœ„í•œ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ í•¨ìˆ˜"""
        delay = 1.0 / (target_fps * st.session_state.playback_speed)
        
        while st.session_state.is_playing and not st.session_state.stop_video:
            if st.session_state.current_frame >= st.session_state.total_frames - 1:
                st.session_state.is_playing = False
                break
                
            st.session_state.current_frame += 1
            time.sleep(delay)
    
    def render_video_analysis_mode(self, settings):
        """ë¹„ë””ì˜¤ ë¶„ì„ ëª¨ë“œ ë Œë”ë§"""
        st.markdown("## ì „ë¬¸ ë¹„ë””ì˜¤ ë¶„ì„")
        
        uploaded_video = st.file_uploader(
            "ë¶„ì„í•  ë¹„ë””ì˜¤ ì—…ë¡œë“œ",
            type=['mp4', 'avi', 'mov', 'mkv'],
            help="ì§€ì› í˜•ì‹: MP4, AVI, MOV, MKV",
            key="video_uploader"
        )
        
        if uploaded_video is not None:
            self.process_uploaded_video_batch(uploaded_video, settings)
    
    def process_uploaded_video_batch(self, uploaded_video, settings):
        """ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¹„ë””ì˜¤ ë¶„ì„"""
        from video import video_detector
        
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name
        
        fps, total_frames, duration = video_detector.get_video_info(video_path)
        
        if total_frames == 0:
            st.error("ë¹„ë””ì˜¤ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        # ë¹„ë””ì˜¤ ì •ë³´ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì´ í”„ë ˆì„", f"{total_frames:,}")
        with col2:
            st.metric("FPS", f"{fps:.1f}")
        with col3:
            st.metric("ê¸¸ì´", f"{duration:.1f}ì´ˆ")
        with col4:
            estimated_time = min(total_frames * 0.2, 500)
            st.metric("ì˜ˆìƒ ì²˜ë¦¬ì‹œê°„", f"{estimated_time:.1f}ì´ˆ")
        
        # ì²˜ë¦¬ ì™„ë£Œ í›„ ìë™ ê²°ê³¼ í‘œì‹œ
        if st.session_state.get('processing_complete', False) and st.session_state.get('batch_results'):
            if st.session_state.get('auto_show_results', True):
                st.success("ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
                self.display_batch_results(
                    st.session_state['batch_results'], 
                    [r['processing_time'] for r in st.session_state['batch_results']]
                )
                return
            else:
                st.success("ì´ì „ ì²˜ë¦¬ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤!")
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ì´ì „ ê²°ê³¼ ë³´ê¸°", type="primary", key="show_prev_results"):
                        st.session_state['auto_show_results'] = True
                        st.rerun()
                with col2:
                    if st.button("ìƒˆë¡œ ì²˜ë¦¬í•˜ê¸°", key="process_new"):
                        st.session_state['processing_complete'] = False
                        st.session_state['batch_results'] = None
                        st.session_state['auto_show_results'] = True
                        st.rerun()
                return
        
        if not st.session_state.get('is_processing', False):
            st.markdown("### ì²˜ë¦¬ ì˜µì…˜")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                process_interval = st.selectbox(
                    "ì²˜ë¦¬ ê°„ê²©",
                    [1, 2, 3, 5, 10],
                    index=2,
                    help="N í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ (ê°„ê²©ì´ í´ìˆ˜ë¡ ë¹¨ë¼ì§)",
                    key="process_interval_select"
                )
            
            with col2:
                # ìµœëŒ€ í”„ë ˆì„ ì œí•œì„ ëŒ€í­ í™•ì¥í•˜ê³  "ì „ì²´" ì˜µì…˜ ì¶”ê°€
                max_frames_options = [100, 500, 1000, 2000, 5000, total_frames]
                max_frames_labels = ["100ê°œ", "500ê°œ", "1000ê°œ", "2000ê°œ", "5000ê°œ", f"ì „ì²´ ({total_frames}ê°œ)"]
                
                max_frames_idx = st.selectbox(
                    "ìµœëŒ€ ì²˜ë¦¬ í”„ë ˆì„",
                    range(len(max_frames_options)),
                    index=2,  # ê¸°ë³¸ê°’ì„ 1000ê°œë¡œ ì„¤ì •
                    format_func=lambda x: max_frames_labels[x],
                    help="ì²˜ë¦¬í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜",
                    key="max_frames_select"
                )
                max_frames = max_frames_options[max_frames_idx]
            
            with col3:
                confidence = st.slider(
                    "ì‹ ë¢°ë„ ì„ê³„ê°’",
                    0.3, 0.8, 0.5, 0.1,
                    help="íƒì§€ ì‹ ë¢°ë„ ì„¤ì •",
                    key="confidence_select"
                )
            
            # ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            frames_to_process = min(total_frames, max_frames) // process_interval
            estimated_time_seconds = frames_to_process * 0.2
            estimated_minutes = estimated_time_seconds / 60
            
            st.info(f"ì˜ˆìƒ ì²˜ë¦¬ í”„ë ˆì„: {frames_to_process:,}ê°œ | ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_minutes:.1f}ë¶„")
            
            if st.button("ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘", type="primary", key="start_processing"):
                st.session_state['is_processing'] = True
                st.session_state['processing_complete'] = False
                st.session_state['auto_show_results'] = True  # ì²˜ë¦¬ ì™„ë£Œ í›„ ìë™ í‘œì‹œ
                st.session_state['process_params'] = {
                    'video_path': video_path,
                    'fps': fps,
                    'total_frames': total_frames,
                    'process_interval': process_interval,
                    'max_frames': max_frames,
                    'confidence': confidence
                }
                st.rerun()
        
        # ì²˜ë¦¬ ì‹¤í–‰
        if st.session_state.get('is_processing', False):
            params = st.session_state.get('process_params', {})
            results = self.batch_process_video(**params)
            
            if results:
                st.session_state['batch_results'] = results
                st.session_state['processing_complete'] = True
                st.session_state['is_processing'] = False
                # ì²˜ë¦¬ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
                st.success("ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
                st.rerun()
            else:
                st.session_state['is_processing'] = False
                st.error("ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    def batch_process_video(self, video_path, fps, total_frames, process_interval, max_frames, confidence):
        """ë¹„ë””ì˜¤ë¥¼ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ë°˜í™˜"""
        from video import video_detector
        
        frames_to_process = list(range(0, min(total_frames, max_frames), process_interval))
        total_process_frames = len(frames_to_process)
        
        st.markdown("### ì²˜ë¦¬ ì§„í–‰ìƒí™©")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        processed_results = []
        processing_times = []
        
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            st.error("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            for i, frame_num in enumerate(frames_to_process):
                progress = (i + 1) / total_process_frames
                progress_bar.progress(progress)
                status_text.text(f"ì²˜ë¦¬ ì¤‘: {i+1}/{total_process_frames} í”„ë ˆì„ (í”„ë ˆì„ #{frame_num})")
                
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                ret, frame = cap.read()
                
                if not ret:
                    continue
                
                start_time = time.time()
                result_img, detections = video_detector.detect_objects_optimized(frame, confidence)
                processing_time = time.time() - start_time
                
                result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                frame_time = frame_num / fps
                
                processed_results.append({
                    'frame_number': frame_num,
                    'time': frame_time,
                    'image': result_rgb,
                    'original_image': cv2.cvtColor(frame, cv2.COLOR_BGR2RGB),
                    'processed_image_bgr': result_img,
                    'detections': detections,
                    'processing_time': processing_time,
                    'people_count': len(video_detector.detected_people),
                    'segmented_count': len(video_detector.segmented_people),
                    'mask_count': len(video_detector.mask_wearers)
                })
                
                processing_times.append(processing_time)
                
                if (i + 1) % 10 == 0:
                    avg_time = sum(processing_times) / len(processing_times) if processing_times else 0
                    remaining_frames = total_process_frames - (i + 1)
                    estimated_remaining = remaining_frames * avg_time
                    status_text.text(f"ì²˜ë¦¬ ì¤‘: {i+1}/{total_process_frames} í”„ë ˆì„ - ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining:.1f}ì´ˆ")
        
        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
        finally:
            cap.release()
        
        progress_bar.progress(1.0)
        status_text.text(f"ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(processed_results)}ê°œ í”„ë ˆì„ ì²˜ë¦¬ë¨")
        
        return processed_results
    
    # def create_processed_video(self, results, fps):
    #     """ì²˜ë¦¬ëœ í”„ë ˆì„ë“¤ë¡œë¶€í„° ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„±"""
    #     import io
        
    #     if not results:
    #         return None
            
    #     try:
    #         temp_video = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    #         temp_video_path = temp_video.name
    #         temp_video.close()
            
    #         first_frame = results[0]['processed_image_bgr']
    #         height, width = first_frame.shape[:2]
            
    #         fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    #         out = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
            
    #         for result in results:
    #             if 'processed_image_bgr' in result:
    #                 out.write(result['processed_image_bgr'])
            
    #         out.release()
            
    #         with open(temp_video_path, 'rb') as f:
    #             video_bytes = f.read()
            
    #         os.unlink(temp_video_path)
            
    #         return video_bytes
            
    #     except Exception as e:
    #         st.error(f"ë¹„ë””ì˜¤ ìƒì„± ì˜¤ë¥˜: {e}")
    #         return None
    def create_processed_video(self, results, fps):
        """ì²˜ë¦¬ëœ í”„ë ˆì„ë“¤ë¡œë¶€í„° H.264 ì½”ë±ì„ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„±"""
        import io
        
        if not results:
            return None
            
        try:
            temp_video = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            temp_video_path = temp_video.name
            temp_video.close()
            
            first_frame = results[0]['processed_image_bgr']
            height, width = first_frame.shape[:2]
            
            # H.264 ì½”ë± ì§€ì • (ë” í˜¸í™˜ì„±ì´ ë†’ì€ ë°©ë²•ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„)
            codecs_to_try = [
                ('H264', cv2.VideoWriter_fourcc(*'H264')),  # H.264 ì§ì ‘ ì§€ì •
                ('avc1', cv2.VideoWriter_fourcc(*'avc1')),  # H.264 (Apple í˜¸í™˜)
                ('mp4v', cv2.VideoWriter_fourcc(*'mp4v')),  # MPEG-4 Part 2 (fallback)
                ('XVID', cv2.VideoWriter_fourcc(*'XVID'))   # Xvid (ìµœì¢… fallback)
            ]
            
            video_writer = None
            used_codec = None
            
            for codec_name, fourcc in codecs_to_try:
                try:
                    test_writer = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
                    
                    # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ì‘ì„±í•´ë³´ê¸°
                    if test_writer.isOpened():
                        test_writer.write(first_frame)
                        test_writer.release()
                        
                        # íŒŒì¼ì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if os.path.getsize(temp_video_path) > 0:
                            video_writer = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
                            used_codec = codec_name
                            st.info(f"ë¹„ë””ì˜¤ ì½”ë±: {codec_name} ì‚¬ìš©")
                            break
                    else:
                        test_writer.release()
                        
                except Exception as e:
                    st.warning(f"{codec_name} ì½”ë± ì‚¬ìš© ì‹¤íŒ¨: {e}")
                    continue
            
            if video_writer is None or not video_writer.isOpened():
                st.error("ì§€ì›ë˜ëŠ” ë¹„ë””ì˜¤ ì½”ë±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            try:
                # ëª¨ë“  í”„ë ˆì„ ì‘ì„±
                frames_written = 0
                for result in results:
                    if 'processed_image_bgr' in result:
                        video_writer.write(result['processed_image_bgr'])
                        frames_written += 1
                
                video_writer.release()
                
                # ìƒì„±ëœ íŒŒì¼ í¬ê¸° í™•ì¸
                file_size = os.path.getsize(temp_video_path)
                if file_size == 0:
                    st.error("ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (íŒŒì¼ í¬ê¸°: 0)")
                    return None
                
                st.success(f"ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {frames_written}ê°œ í”„ë ˆì„, {file_size/1024/1024:.2f}MB, ì½”ë±: {used_codec}")
                
                # íŒŒì¼ ì½ê¸°
                with open(temp_video_path, 'rb') as f:
                    video_bytes = f.read()
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.unlink(temp_video_path)
                
                return video_bytes
                
            except Exception as e:
                st.error(f"ë¹„ë””ì˜¤ ì‘ì„± ì¤‘ ì˜¤ë¥˜: {e}")
                video_writer.release()
                if os.path.exists(temp_video_path):
                    os.unlink(temp_video_path)
                return None
                
        except Exception as e:
            st.error(f"ë¹„ë””ì˜¤ ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    
    def display_batch_results(self, results, processing_times):
        """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ"""
        if not results:
            st.warning("ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        st.markdown("### ì²˜ë¦¬ ê²°ê³¼")
        
        # ìƒˆë¡œ ì²˜ë¦¬í•˜ê¸° ë²„íŠ¼
        if st.button("ìƒˆ ë¹„ë””ì˜¤ ì²˜ë¦¬í•˜ê¸°", key="new_video_btn"):
            st.session_state['processing_complete'] = False
            st.session_state['batch_results'] = None
            st.session_state['auto_show_results'] = True
            st.rerun()
        
        # í†µê³„ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì²˜ë¦¬ëœ í”„ë ˆì„", len(results))
        with col2:
            avg_time = sum(processing_times) / len(processing_times) if processing_times else 0
            st.metric("í‰ê·  ì²˜ë¦¬ì‹œê°„", f"{avg_time:.3f}ì´ˆ")
        with col3:
            total_people = sum(r['people_count'] for r in results)
            st.metric("ì´ íƒì§€ëœ ì‚¬ëŒ", total_people)
        with col4:
            total_masks = sum(r['mask_count'] for r in results)
            st.metric("ì´ ë§ˆìŠ¤í¬ íƒì§€", total_masks)
        
        # ê²°ê³¼ íƒìƒ‰ ì¸í„°í˜ì´ìŠ¤
        st.markdown("### ê²°ê³¼ íƒìƒ‰")
        
        if len(results) > 1:
            selected_idx = st.slider(
                "í”„ë ˆì„ ì„ íƒ",
                0, len(results) - 1, 0,
                format="í”„ë ˆì„ %d",
                key="frame_selector"
            )
        else:
            selected_idx = 0
        
        if 0 <= selected_idx < len(results):
            result = results[selected_idx]
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown(f"#### í”„ë ˆì„ #{result['frame_number']} (ì‹œê°„: {result['time']:.2f}ì´ˆ)")
                
                tab1, tab2 = st.tabs(["ì²˜ë¦¬ ê²°ê³¼", "ì›ë³¸"])
                
                with tab1:
                    st.image(result['image'], use_container_width=True, caption="ì²˜ë¦¬ëœ ì´ë¯¸ì§€")
                
                with tab2:
                    if 'original_image' in result:
                        st.image(result['original_image'], use_container_width=True, caption="ì›ë³¸ ì´ë¯¸ì§€")
                
                st.markdown("**íƒì§€ ì •ë³´:**")
                st.write(f"- ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.3f}ì´ˆ")
                st.write(f"- íƒì§€ëœ ì‚¬ëŒ: {result['people_count']}ëª…")
                st.write(f"- ì„¸ê·¸ë©˜í…Œì´ì…˜: {result['segmented_count']}ëª…")
                st.write(f"- ë§ˆìŠ¤í¬ ì°©ìš©: {result['mask_count']}ëª…")
            
            with col2:
                st.markdown("#### í”„ë ˆì„ ë¶„ì„")
                
                if not result['detections'].empty:
                    detection_summary = result['detections']['name'].value_counts()
                    for obj_type, count in detection_summary.items():
                        st.write(f"- {obj_type}: {count}ê°œ")
                else:
                    st.write("íƒì§€ëœ ê°ì²´ ì—†ìŒ")
                
                if not result['detections'].empty and 'confidence' in result['detections'].columns:
                    st.markdown("**ì‹ ë¢°ë„ ë¶„í¬**")
                    fig = px.histogram(
                        result['detections'], 
                        x='confidence',
                        title="",
                        nbins=10
                    )
                    fig.update_layout(height=200, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True, key="confidence_histogram")
        
        # ì „ì²´ ì²˜ë¦¬ í†µê³„ ì°¨íŠ¸
        st.markdown("### ì „ì²´ ë¶„ì„ ê²°ê³¼")
        
        if len(results) > 1:
            # ì‹œê°„ë³„ ì²˜ë¦¬ ì„±ëŠ¥ ì°¨íŠ¸
            times_df = pd.DataFrame({
                'í”„ë ˆì„': [r['frame_number'] for r in results],
                'ì²˜ë¦¬ì‹œê°„': [r['processing_time'] for r in results],
                'íƒì§€ëœì‚¬ëŒ': [r['people_count'] for r in results],
                'ë§ˆìŠ¤í¬ì°©ìš©': [r['mask_count'] for r in results]
            })
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ì²˜ë¦¬ ì‹œê°„ ì¶”ì´
                fig1 = px.line(times_df, x='í”„ë ˆì„', y='ì²˜ë¦¬ì‹œê°„', title="í”„ë ˆì„ë³„ ì²˜ë¦¬ ì‹œê°„")
                st.plotly_chart(fig1, use_container_width=True, key="processing_time_chart")
            
            with col2:
                # íƒì§€ ê²°ê³¼ ì¶”ì´
                fig2 = px.line(times_df, x='í”„ë ˆì„', y=['íƒì§€ëœì‚¬ëŒ', 'ë§ˆìŠ¤í¬ì°©ìš©'], 
                              title="í”„ë ˆì„ë³„ íƒì§€ ê²°ê³¼")
                st.plotly_chart(fig2, use_container_width=True, key="detection_results_chart")
        
        # ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
        st.markdown("### ê²°ê³¼ ì €ì¥")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # CSV ë‹¤ìš´ë¡œë“œ - ì§ì ‘ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            summary_data = []
            for r in results:
                summary_data.append({
                    'í”„ë ˆì„ë²ˆí˜¸': r['frame_number'],
                    'ì‹œê°„': f"{r['time']:.2f}",
                    'ì²˜ë¦¬ì‹œê°„': f"{r['processing_time']:.3f}",
                    'íƒì§€ëœì‚¬ëŒ': r['people_count'],
                    'ì„¸ê·¸ë©˜í…Œì´ì…˜': r['segmented_count'],
                    'ë§ˆìŠ¤í¬ì°©ìš©': r['mask_count']
                })
            
            df_summary = pd.DataFrame(summary_data)
            csv = df_summary.to_csv(index=False, encoding='utf-8-sig')
            
            st.download_button(
                label="CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"video_analysis_results_{int(time.time())}.csv",
                mime="text/csv",
                key="results_csv_download"
            )
        
        with col2:
            # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
            if st.button("ì²˜ë¦¬ëœ ë¹„ë””ì˜¤ ìƒì„±", key="create_video_btn"):
                with st.spinner("ë¹„ë””ì˜¤ ìƒì„± ì¤‘..."):
                    # FPS ê³„ì‚°
                    fps = 30.0
                    if len(results) > 1:
                        time_diff = results[1]['time'] - results[0]['time']
                        if time_diff > 0:
                            fps = min(1.0 / time_diff, 30.0)
                    
                    video_bytes = self.create_processed_video(results, fps)
                    
                    if video_bytes:
                        st.download_button(
                            label="MP4 íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                            data=video_bytes,
                            file_name=f"processed_video_{int(time.time())}.mp4",
                            mime="video/mp4",
                            key="results_video_download"
                        )
                        st.success("ë¹„ë””ì˜¤ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.error("ë¹„ë””ì˜¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
    def render_video_player_controls(self, settings):
        """ë¹„ë””ì˜¤ í”Œë ˆì´ì–´ ì»¨íŠ¸ë¡¤ UI ë Œë”ë§"""
        st.markdown("### ì¬ìƒ ì»¨íŠ¸ë¡¤")
        
        col1, col2, col3, col4, col5 = st.columns([2, 1, 1, 1, 1])
        
        # ì¬ìƒ/ì¼ì‹œì •ì§€ ë²„íŠ¼
        with col1:
            play_button_text = "ì¼ì‹œì •ì§€" if st.session_state.is_playing else "ì¬ìƒ"
            if st.button(play_button_text, type="primary", key="play_button"):
                if not st.session_state.is_playing:
                    st.session_state.is_playing = True
                    st.session_state.stop_video = False
                    if st.session_state.video_playing_thread is None or not st.session_state.video_playing_thread.is_alive():
                        st.session_state.video_playing_thread = threading.Thread(
                            target=self.video_playback_thread,
                            args=(st.session_state.video_path, settings['target_fps'], True, settings['confidence_threshold'])
                        )
                        st.session_state.video_playing_thread.daemon = True
                        st.session_state.video_playing_thread.start()
                else:
                    st.session_state.is_playing = False
                st.rerun()
        
        # ì •ì§€ ë²„íŠ¼
        with col2:
            if st.button("ì •ì§€", key="stop_button"):
                st.session_state.is_playing = False
                st.session_state.stop_video = True
                st.session_state.current_frame = 0
                st.rerun()
        
        # ì¬ìƒ ì†ë„ ì„ íƒ
        with col3:
            speed_options = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]
            speed_index = speed_options.index(st.session_state.playback_speed) if st.session_state.playback_speed in speed_options else 2
            new_speed = st.selectbox(
                "ì†ë„",
                speed_options,
                index=speed_index,
                format_func=lambda x: f"{x}ë°°ì†",
                key="playback_speed_selector"
            )
            st.session_state.playback_speed = new_speed
        
        # ì‹¤ì‹œê°„ íƒì§€ í™œì„±í™” ì²´í¬ë°•ìŠ¤
        with col4:
            enable_detection = st.checkbox("ì‹¤ì‹œê°„ íƒì§€", value=True, key="enable_detection_checkbox")
        
        # ë¶„ì„ í‘œì‹œ ì²´í¬ë°•ìŠ¤
        with col5:
            show_analytics = st.checkbox("ë¶„ì„", value=True, key="show_analytics_checkbox")
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” (ë¹„ë””ì˜¤ ìœ„ì¹˜ ì¡°ì ˆ)
        if st.session_state.total_frames > 0:
            progress = st.slider(
                "ìœ„ì¹˜",
                0, st.session_state.total_frames - 1,
                st.session_state.current_frame,
                format="í”„ë ˆì„ %d",
                key="video_progress_slider"
            )
            
            # ì‚¬ìš©ìê°€ ìŠ¬ë¼ì´ë”ë¥¼ ì¡°ì‘í•œ ê²½ìš°
            if progress != st.session_state.current_frame:
                st.session_state.current_frame = progress
                st.session_state.is_playing = False
                st.session_state.stop_video = True
        
        return enable_detection, show_analytics
    
    def render_video_display(self, enable_detection=True, confidence_threshold=0.5):
        """ë¹„ë””ì˜¤ í”„ë ˆì„ í‘œì‹œ ì˜ì—­"""
        if not st.session_state.video_path:
            return
        
        from video import video_detector
        
        # í˜„ì¬ í”„ë ˆì„ ìœ„ì¹˜ì—ì„œ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        frame = video_detector.get_frame_at_position(
            st.session_state.video_path,
            st.session_state.current_frame
        )
        
        if frame is not None:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.markdown("### ë¹„ë””ì˜¤ í”„ë ˆì„ ë¶„ì„")
                
                # í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘
                start_time = time.time()
                if enable_detection:
                    result_img, detections = video_detector.detect_objects_optimized(frame, confidence_threshold)
                else:
                    result_img = frame
                    detections = pd.DataFrame()
                processing_time = time.time() - start_time
                
                # BGRì—ì„œ RGBë¡œ ë³€í™˜í•˜ì—¬ ê²°ê³¼ í‘œì‹œ
                result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)
                
                # í”„ë ˆì„ ì •ë³´ë¥¼ í¬í•¨í•œ ìº¡ì…˜ ìƒì„±
                current_time = st.session_state.current_frame / st.session_state.fps
                caption = f"í”„ë ˆì„ {st.session_state.current_frame + 1} | ì‹œê°„: {current_time:.2f}ì´ˆ | ê°ì²´: {len(detections)} | ì²˜ë¦¬ì‹œê°„: {processing_time:.3f}ì´ˆ"
                
                st.image(result_rgb, caption=caption, use_container_width=True)
                
                # ì¬ìƒ ì¤‘ì¼ ë•Œ ìë™ ìƒˆë¡œê³ ì¹¨
                if st.session_state.is_playing:
                    time.sleep(0.1)
                    st.rerun()
            
            with col2:
                st.markdown("### í”„ë ˆì„ ë¶„ì„")
                
                # ì‹¤ì‹œê°„ í†µê³„ í‘œì‹œ
                stages = ['ì‚¬ëŒ íƒì§€', 'ì„¸ê·¸ë©˜í…Œì´ì…˜', 'ë§ˆìŠ¤í¬ íƒì§€']
                counts = [
                    len(video_detector.detected_people),
                    len(video_detector.segmented_people),
                    len(video_detector.mask_wearers)
                ]
                
                # ê° ë‹¨ê³„ë³„ ìƒíƒœ í‘œì‹œ
                for stage, count in zip(stages, counts):
                    color = "ë…¹ìƒ‰" if count > 0 else "ë¹¨ê°„ìƒ‰"
                    st.write(f"{color} {stage}: {count}")
                
                # ì²˜ë¦¬ ì‹œê°„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
                if 'processing_times' not in st.session_state:
                    st.session_state.processing_times = []
                
                if enable_detection:
                    st.session_state.processing_times.append(processing_time)
                    # ìµœê·¼ 50ê°œ ê¸°ë¡ë§Œ ìœ ì§€
                    if len(st.session_state.processing_times) > 50:
                        st.session_state.processing_times.pop(0)
                
                # ì²˜ë¦¬ ì‹œê°„ ì¶”ì´ ë¯¸ë‹ˆ ì°¨íŠ¸
                if len(st.session_state.processing_times) > 5:
                    fig = px.line(
                        y=st.session_state.processing_times[-20:],
                        title="ì²˜ë¦¬ ì‹œê°„ ì¶”ì´",
                        labels={'y': 'ì‹œê°„ (ì´ˆ)', 'index': 'í”„ë ˆì„'}
                    )
                    fig.update_layout(height=200, showlegend=False)
                    st.plotly_chart(fig, use_container_width=True, key="realtime_processing_chart")
                
                # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ (íƒì§€ê°€ í™œì„±í™”ëœ ê²½ìš°ë§Œ)
                if enable_detection:
                    self.update_performance_metrics(processing_time, len(detections))
    
    def update_performance_metrics(self, processing_time, detection_count):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        metrics = st.session_state.performance_metrics
        metrics['total_processed'] += 1
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° (ì ì§„ì  í‰ê· )
        if metrics['avg_processing_time'] == 0:
            metrics['avg_processing_time'] = processing_time
        else:
            metrics['avg_processing_time'] = (metrics['avg_processing_time'] + processing_time) / 2
    
    def render_analytics_dashboard(self):
        """ë¶„ì„ ëŒ€ì‹œë³´ë“œ ë Œë”ë§"""
        st.markdown("## ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
        
        # ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ì™€ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê²°ê³¼ í†µí•© í™•ì¸
        has_batch_data = st.session_state.get('batch_results') is not None and len(st.session_state.get('batch_results', [])) > 0
        has_realtime_data = st.session_state.get('processing_times') is not None and len(st.session_state.get('processing_times', [])) > 1
        
        if not has_batch_data and not has_realtime_data:
            st.info("ì²˜ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë‚˜ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")
            return
        
        # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ íƒ­
        if has_batch_data and has_realtime_data:
            data_tab1, data_tab2 = st.tabs(["ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼", "ì‹¤ì‹œê°„ ì²˜ë¦¬ ê²°ê³¼"])
            
            with data_tab1:
                self.render_batch_analytics()
            
            with data_tab2:
                self.render_realtime_analytics()
        elif has_batch_data:
            st.markdown("### ë°°ì¹˜ ì²˜ë¦¬ ë¶„ì„ ê²°ê³¼")
            self.render_batch_analytics()
        else:
            st.markdown("### ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶„ì„ ê²°ê³¼")
            self.render_realtime_analytics()
    
    def render_batch_analytics(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë¶„ì„ ë Œë”ë§"""
        batch_results = st.session_state.get('batch_results', [])
        
        if not batch_results:
            st.warning("ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ ì°¨íŠ¸
            batch_df = pd.DataFrame({
                'í”„ë ˆì„ë²ˆí˜¸': [r['frame_number'] for r in batch_results],
                'ì²˜ë¦¬ì‹œê°„': [r['processing_time'] for r in batch_results],
                'íƒì§€ëœì‚¬ëŒ': [r['people_count'] for r in batch_results],
                'ì„¸ê·¸ë©˜í…Œì´ì…˜': [r['segmented_count'] for r in batch_results],
                'ë§ˆìŠ¤í¬ì°©ìš©': [r['mask_count'] for r in batch_results],
                'ì‹œê°„': [r['time'] for r in batch_results]
            })
            
            # ì²˜ë¦¬ ì„±ëŠ¥ ì°¨íŠ¸
            fig1 = px.line(batch_df, x='ì‹œê°„', y='ì²˜ë¦¬ì‹œê°„', 
                          title="ì‹œê°„ë³„ ì²˜ë¦¬ ì„±ëŠ¥ (ë°°ì¹˜ ì²˜ë¦¬)")
            fig1.update_layout(height=300)
            st.plotly_chart(fig1, use_container_width=True, key="batch_performance_chart")
            
            # íƒì§€ ê²°ê³¼ ì¶”ì´ ì°¨íŠ¸
            fig2 = px.line(batch_df, x='ì‹œê°„', y=['íƒì§€ëœì‚¬ëŒ', 'ì„¸ê·¸ë©˜í…Œì´ì…˜', 'ë§ˆìŠ¤í¬ì°©ìš©'], 
                          title="ì‹œê°„ë³„ íƒì§€ ê²°ê³¼ ì¶”ì´")
            fig2.update_layout(height=300)
            st.plotly_chart(fig2, use_container_width=True, key="batch_detection_trend")
            
        with col2:
            # ë°°ì¹˜ ì²˜ë¦¬ í†µê³„
            st.markdown("### ë°°ì¹˜ ì²˜ë¦¬ í†µê³„")
            
            processing_times = [r['processing_time'] for r in batch_results]
            total_people = sum(r['people_count'] for r in batch_results)
            total_segments = sum(r['segmented_count'] for r in batch_results)
            total_masks = sum(r['mask_count'] for r in batch_results)
            
            st.metric("ì²˜ë¦¬ëœ í”„ë ˆì„", len(batch_results))
            st.metric("ì´ ì²˜ë¦¬ ì‹œê°„", f"{sum(processing_times):.2f}ì´ˆ")
            st.metric("í‰ê·  ì²˜ë¦¬ ì‹œê°„", f"{np.mean(processing_times):.3f}ì´ˆ")
            st.metric("ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„", f"{max(processing_times):.3f}ì´ˆ")
            st.metric("ìµœì†Œ ì²˜ë¦¬ ì‹œê°„", f"{min(processing_times):.3f}ì´ˆ")
            
            st.markdown("### íƒì§€ í†µê³„")
            st.metric("ì´ ì‚¬ëŒ íƒì§€", total_people)
            st.metric("ì´ ì„¸ê·¸ë©˜í…Œì´ì…˜", total_segments)
            st.metric("ì´ ë§ˆìŠ¤í¬ íƒì§€", total_masks)
            
            # íƒì§€ ì„±ê³µë¥  ê³„ì‚°
            if len(batch_results) > 0:
                people_success_rate = (sum(1 for r in batch_results if r['people_count'] > 0) / len(batch_results)) * 100
                mask_success_rate = (sum(1 for r in batch_results if r['mask_count'] > 0) / len(batch_results)) * 100
                
                st.markdown("### ì„±ê³µë¥ ")
                st.metric("ì‚¬ëŒ íƒì§€ ì„±ê³µë¥ ", f"{people_success_rate:.1f}%")
                st.metric("ë§ˆìŠ¤í¬ íƒì§€ ì„±ê³µë¥ ", f"{mask_success_rate:.1f}%")
    
    def render_realtime_analytics(self):
        """ì‹¤ì‹œê°„ ì²˜ë¦¬ ê²°ê³¼ ë¶„ì„ ë Œë”ë§"""
        processing_times = st.session_state.get('processing_times', [])
        
        if len(processing_times) < 2:
            st.warning("ì‹¤ì‹œê°„ ì²˜ë¦¬ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # ì‹¤ì‹œê°„ ì²˜ë¦¬ íˆìŠ¤í† ë¦¬ ì°¨íŠ¸
            df_times = pd.DataFrame({
                'í”„ë ˆì„': range(len(processing_times)),
                'ì²˜ë¦¬ì‹œê°„': processing_times
            })
            fig = px.line(df_times, x='í”„ë ˆì„', y='ì²˜ë¦¬ì‹œê°„', 
                         title="ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥")
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True, key="realtime_performance_chart")
        
        with col2:
            # ì‹¤ì‹œê°„ ì²˜ë¦¬ í†µê³„
            st.markdown("### ì‹¤ì‹œê°„ ì²˜ë¦¬ í†µê³„")
            metrics = st.session_state.performance_metrics
            
            st.metric("ì´ ì²˜ë¦¬ë¨", metrics['total_processed'])
            st.metric("í‰ê·  ì²˜ë¦¬ì‹œê°„", f"{metrics['avg_processing_time']:.3f}ì´ˆ")
            
            # í˜„ì¬ ì„¸ì…˜ì˜ ì²˜ë¦¬ ì‹œê°„ í†µê³„
            avg_time = np.mean(processing_times)
            max_time = max(processing_times)
            min_time = min(processing_times)
            
            st.metric("í˜„ì¬ ì„¸ì…˜ í‰ê· ", f"{avg_time:.3f}ì´ˆ")
            st.metric("ìµœëŒ€ ì²˜ë¦¬ ì‹œê°„", f"{max_time:.3f}ì´ˆ")
            st.metric("ìµœì†Œ ì²˜ë¦¬ ì‹œê°„", f"{min_time:.3f}ì´ˆ")
            
            # ì²˜ë¦¬ ì‹œê°„ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
            if len(processing_times) > 10:
                st.markdown("### ì²˜ë¦¬ ì‹œê°„ ë¶„í¬")
                fig_hist = px.histogram(
                    x=processing_times,
                    nbins=20,
                    title="ì²˜ë¦¬ ì‹œê°„ ë¶„í¬"
                )
                fig_hist.update_layout(height=250, showlegend=False)
                st.plotly_chart(fig_hist, use_container_width=True, key="processing_time_histogram")
    
    def run(self):
        """ë©”ì¸ UI ì‹¤í–‰ í•¨ìˆ˜"""
        # ë©”ì¸ í—¤ë” ë Œë”ë§
        self.render_header()
        
        # ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ê°’ë“¤ ê°€ì ¸ì˜¤ê¸°
        settings = self.render_advanced_sidebar()
        
        # ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œê°í™” ë Œë”ë§
        self.render_processing_pipeline_visual()
        
        # ë©”ì¸ íƒ­ êµ¬ì„± (ì´ë¯¸ì§€ ë¶„ì„, ë¹„ë””ì˜¤ ë¶„ì„, ì‹¤ì‹œê°„ ë¶„ì„)
        tab1, tab2, tab3 = st.tabs(["ì´ë¯¸ì§€ ë¶„ì„", "ë¹„ë””ì˜¤ ë¶„ì„", "ì‹¤ì‹œê°„ ë¶„ì„"])
        
        with tab1:
            self.render_image_detection_mode(settings)
        
        with tab2:
            self.render_video_analysis_mode(settings)
        
        with tab3:
            self.render_analytics_dashboard()

# UI ì‹¤í–‰ í•¨ìˆ˜
def run_video_ui():
    """ê³ ê¸‰ UI ì‹¤í–‰ ì§„ì…ì """
    try:
        ui = PremiumUI()
        ui.run_standalone()
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜¤ë¥˜: {e}")
        st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    run_video_ui()